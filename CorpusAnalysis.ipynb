{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus():\n",
    "    corpus_path = \"./corpus/\"\n",
    "    corpus = PlaintextCorpusReader(corpus_path, \".*\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(subcorpus):\n",
    "    return len(subcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexical_diversity(subcorpus):\n",
    "    # TODO: implement this\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ten_most_frequent_words(subcorpus):\n",
    "    # TODO: implement this\n",
    "    return {\"word1\": 0, \"word2\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_with_at_least_10_characters(subcorpus):\n",
    "    # TODO: implement this\n",
    "    return {\"abcdefghij\": 0, \"klmnopqrstuv\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_sentence(corpus: PlaintextCorpusReader, subcorpus_filename: str):\n",
    "    sentences = corpus.sents(subcorpus_filename)\n",
    "    longest_sentence = max(sentences, key=len)\n",
    "    return longest_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_length(sentence: str):\n",
    "    # TODO: implement this\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_stemmed(sentence: list[str]):\n",
    "    stemmer = PorterStemmer()\n",
    "    sentence_stemmed = [stemmer.stem(word) for word in sentence]\n",
    "    return sentence_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(subcorpus_filename: str):\n",
    "    corpus = load_corpus()\n",
    "    subcorpus = corpus.words(subcorpus_filename)\n",
    "\n",
    "    print(\"Analysis for\", subcorpus_filename)\n",
    "    print(\"\")\n",
    "\n",
    "    length = get_length(subcorpus)\n",
    "    print(\"Length:\", length)\n",
    "    print(\"\")\n",
    "\n",
    "    lexical_diversity = get_lexical_diversity(subcorpus)\n",
    "    print(\"Lexical diversity:\", lexical_diversity)\n",
    "    print(\"\")\n",
    "\n",
    "    top_ten_most_frequent_words = get_top_ten_most_frequent_words(subcorpus)\n",
    "    print(\"Top 10 most frequent words:\")\n",
    "    for word in top_ten_most_frequent_words:\n",
    "        print(word, top_ten_most_frequent_words[word])\n",
    "    print(\"\")\n",
    "\n",
    "    words_with_at_least_10_characters = get_words_with_at_least_10_characters(subcorpus)\n",
    "    print(\"Words with at least 10 characters:\")\n",
    "    for word in words_with_at_least_10_characters:\n",
    "        print(word, words_with_at_least_10_characters[word])\n",
    "    print(\"\")\n",
    "    \n",
    "    longest_sentence = get_longest_sentence(corpus, subcorpus_filename)\n",
    "    longest_sentence_str = \" \".join(longest_sentence)\n",
    "    longest_sentence_length = get_sentence_length(longest_sentence)\n",
    "    print(\"Longest sentence:\", longest_sentence_str)\n",
    "    print(\"The longest sentence is\", longest_sentence_length, \"words long\")\n",
    "    print(\"\")\n",
    "\n",
    "    longest_sentence_stemmed = get_sentence_stemmed(longest_sentence)\n",
    "    longest_sentence_stemmed_str = \" \".join(longest_sentence_stemmed)\n",
    "    print(\"Longest sentence stemmed:\", longest_sentence_stemmed_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for text_spok.txt\n",
      "\n",
      "Length: 1294949\n",
      "\n",
      "Lexical diversity: 0\n",
      "\n",
      "Top 10 most frequent words:\n",
      "word1 0\n",
      "word2 0\n",
      "\n",
      "Words with at least 10 characters:\n",
      "abcdefghij 0\n",
      "klmnopqrstuv 0\n",
      "\n",
      "Longest sentence: They ' ve allowed Missouri to say that for incompetent persons who have not left absolutely clear and explicit instructions that Missouri may say that the only thing that matters is that they live longer and that as long as we can keep them living longer , we must , even if it means suffering , even if it means travail for the @ @ @ @ @ @ @ @ @ @ terrible pain , it does n ' t matter , Missouri may say that preservation of life is it , and then they can make a procedural standard that guarantees that almost everyone ends up in that category , and if the standard is clear and convincing evidence and Missouri chooses to interpret that fairly narrowly , then you have to be able to forecast how you will be dying and what kinds of medical situations will arise and explicitly speak to those , or you wo n ' t reach the standard , thereupon physicians and others providing care can be required to torment people for the simple lack of foresight to have been able to predict things that are thoroughly unpredictable .\n",
      "The longest sentence is 0 words long\n",
      "\n",
      "Longest sentence stemmed: they ' ve allow missouri to say that for incompet person who have not left absolut clear and explicit instruct that missouri may say that the onli thing that matter is that they live longer and that as long as we can keep them live longer , we must , even if it mean suffer , even if it mean travail for the @ @ @ @ @ @ @ @ @ @ terribl pain , it doe n ' t matter , missouri may say that preserv of life is it , and then they can make a procedur standard that guarante that almost everyon end up in that categori , and if the standard is clear and convinc evid and missouri choos to interpret that fairli narrowli , then you have to be abl to forecast how you will be die and what kind of medic situat will aris and explicitli speak to those , or you wo n ' t reach the standard , thereupon physician and other provid care can be requir to torment peopl for the simpl lack of foresight to have been abl to predict thing that are thoroughli unpredict .\n"
     ]
    }
   ],
   "source": [
    "# Replace this with the subcorpus filename you want to analyze\n",
    "subcorpus_filename = \"text_spok.txt\"\n",
    "analyze(subcorpus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
